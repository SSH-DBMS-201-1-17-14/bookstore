输入：{id：字符串}

过程：
1. 得到{ id：字符串关键词的count} 和 {id: 分词}
2. 得到{词：id列表} 

返回：{词：id列表}  { id：字符串关键词的count} 

代码：

```python
import xlrd
import jieba
import re

# 调用时直接调最后一个 inverted_index 函数，返回两个字典：倒排索引表（字典）和每个文档的词频（字典）


'''
输入：{id：字符串}---->{id: 分词} 和 {id: 分词个数}
new_dic:
{'10000':['一个','题目']}
freq_dic:
{'10000':2}
'''
def getterms(dic):
    ids = list(dic.keys())
#     symlist = [' ','\n','（','）','、'，'。','(',')','*','?','<','=','\','<','>']
               
    new_dic = {}
    freq_dic = {}
    for x in ids:
        string =dic[x] 
        new_string = re.sub(r'[^\w\s]', '',string)
        terms = jieba.lcut(new_string)
        while ' ' in terms:
               terms.remove(' ')
        while '\n' in terms:
               terms.remove('\n')
        
        new_dic[x] = terms
        freq_dic[x] = len(terms)
    return new_dic,freq_dic

'''
dic
{
'一个' : ['10000','10005']    
}
'''
# 根据{id:[term1,term2]}进行map reduce
def mapreduce(termsdic):
    idx = list(termsdic.keys())
    
    term_id_list = []  #map
    for x in idx:
        term_list = termsdic[x]
        for term in term_list:
            term_id_list.append([term,x])
            
    dic = {} #reduce
    for x in term_id_list:
        #x[0]:词          x[1]:出现的文档id
        if x[0] not in dic:
            dic[x[0]] = [x[1]]
        else:
            if x[1] not in dic[x[0]]:
                dic[x[0]].append(x[1])
            
    return dic

# 倒排索引，调用时直接调这个，返回倒排索引表（字典）和每个文档的词频（字典）
'''
inverted_index_dic：
{'美丽': ['1000067'],
 '心灵': ['1000067'],
 '三毛': ['1000134', '1009273']}

freqdic ：
{'1000067': 2,
 '1000134': 3}
'''
def inverted_index(dic):
    termsdic,freqdic = getterms(dic)
    inverted_index_dic = mapreduce(termsdic)
    return inverted_index_dic,freqdic 
```

